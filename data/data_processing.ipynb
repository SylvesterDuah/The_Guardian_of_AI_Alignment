{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68485dac-0c53-42b0-82d9-f628548ea4c6",
   "metadata": {},
   "source": [
    "Step 1: Choose & prepare your dataset for NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ae8698-0989-4b3f-b002-6cbf7c04b3d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nx_arangodb\n",
      "  Using cached nx_arangodb-1.3.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting networkx<=3.4,>=3.0 (from nx_arangodb)\n",
      "  Downloading networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting phenolrs~=0.5 (from nx_arangodb)\n",
      "  Using cached phenolrs-0.5.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.7 kB)\n",
      "Collecting python-arango~=8.1 (from nx_arangodb)\n",
      "  Using cached python_arango-8.1.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting adbnx-adapter~=5.0.5 (from nx_arangodb)\n",
      "  Using cached adbnx_adapter-5.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting requests>=2.27.1 (from adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich>=12.5.1 (from adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting setuptools>=45 (from adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Downloading setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting numpy~=1.26 (from phenolrs~=0.5->nx_arangodb)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting urllib3>=1.26.0 (from python-arango~=8.1->nx_arangodb)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting requests_toolbelt (from python-arango~=8.1->nx_arangodb)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting PyJWT (from python-arango~=8.1->nx_arangodb)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting importlib_metadata>=4.7.1 (from python-arango~=8.1->nx_arangodb)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from python-arango~=8.1->nx_arangodb) (24.2)\n",
      "Collecting zipp>=3.20 (from importlib_metadata>=4.7.1->python-arango~=8.1->nx_arangodb)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx_arangodb) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx_arangodb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached nx_arangodb-1.3.0-py3-none-any.whl (67 kB)\n",
      "Using cached adbnx_adapter-5.0.6-py3-none-any.whl (21 kB)\n",
      "Downloading networkx-3.4-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m248.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached phenolrs-0.5.9-cp312-cp312-macosx_11_0_arm64.whl (2.3 MB)\n",
      "Using cached python_arango-8.1.4-py3-none-any.whl (116 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: zipp, urllib3, setuptools, PyJWT, numpy, networkx, mdurl, idna, charset-normalizer, certifi, requests, markdown-it-py, importlib_metadata, rich, requests_toolbelt, python-arango, phenolrs, adbnx-adapter, nx_arangodb\n",
      "Successfully installed PyJWT-2.10.1 adbnx-adapter-5.0.6 certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 importlib_metadata-8.6.1 markdown-it-py-3.0.0 mdurl-0.1.2 networkx-3.4 numpy-1.26.4 nx_arangodb-1.3.0 phenolrs-0.5.9 python-arango-8.1.4 requests-2.32.3 requests_toolbelt-1.0.0 rich-13.9.4 setuptools-75.8.0 urllib3-2.3.0 zipp-3.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nx_arangodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e09935-ec34-4f22-8583-4ffa4e7b19df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Using cached pymongo-4.11.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Using cached pymongo-4.11.1-cp312-cp312-macosx_11_0_arm64.whl (895 kB)\n",
      "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae461e8-e25a-4712-9468-a85174a61d91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bson\n",
      "  Using cached bson-0.5.10-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.4.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from bson) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from bson) (1.17.0)\n",
      "Installing collected packages: bson\n",
      "Successfully installed bson-0.5.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7ba0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.1 tzdata-2025.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a407046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.0-cp312-cp312-macosx_11_0_arm64.whl (8.0 MB)\n",
      "Using cached contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp312-cp312-macosx_10_13_universal2.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b28f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.71-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 (from langgraph)\n",
      "  Downloading langchain_core-0.3.35-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.13-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.51-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langgraph-0.2.71-py3-none-any.whl (149 kB)\n",
      "Downloading langchain_core-0.3.35-py3-none-any.whl (413 kB)\n",
      "Downloading langgraph_checkpoint-2.0.13-py3-none-any.whl (38 kB)\n",
      "Downloading langgraph_sdk-0.1.51-py3-none-any.whl (44 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl (82 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.5/633.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, typing-extensions, tenacity, sniffio, PyYAML, orjson, msgpack, jsonpointer, h11, annotated-types, pydantic-core, jsonpatch, httpcore, anyio, pydantic, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.8.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.35 langgraph-0.2.71 langgraph-checkpoint-2.0.13 langgraph-sdk-0.1.51 langsmith-0.3.8 msgpack-1.1.0 orjson-3.10.15 pydantic-2.10.6 pydantic-core-2.27.2 sniffio-1.3.1 tenacity-9.0.0 typing-extensions-4.12.2 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94c2a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-openai) (0.3.35)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
      "  Downloading openai-1.62.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached jiter-0.8.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
      "Downloading langchain_openai-0.3.5-py3-none-any.whl (54 kB)\n",
      "Downloading openai-1.62.0-py3-none-any.whl (464 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.6/982.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.8.2-cp312-cp312-macosx_11_0_arm64.whl (310 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 langchain-openai-0.3.5 openai-1.62.0 regex-2024.11.6 tiktoken-0.8.0 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ac99dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-community) (0.3.35)\n",
      "Collecting langchain<1.0.0,>=0.3.18 (from langchain-community)\n",
      "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Downloading SQLAlchemy-2.0.38-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.11.12-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-community) (0.3.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<1.0.0,>=0.3.18->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sylvesterduah/Documents/Code/De_Alignment/align/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.12-cp312-cp312-macosx_11_0_arm64.whl (456 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl (92 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: SQLAlchemy, python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 attrs-25.1.0 dataclasses-json-0.6.7 frozenlist-1.5.0 httpx-sse-0.4.0 langchain-0.3.18 langchain-community-0.3.17 langchain-text-splitters-0.3.6 marshmallow-3.26.1 multidict-6.1.0 mypy-extensions-1.0.0 propcache-0.2.1 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0 yarl-1.18.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f33e37e-8048-4e48-b3ef-384553e1231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis module imports necessary libraries and modules for graph processing,\\ndata manipulation, visualization, and language model interactions.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "# Third-party imports\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from bson import loads\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import nx_arangodb as nxadb\n",
    "from arango import ArangoClient\n",
    "\n",
    "# LangChain related imports\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\"\"\"\n",
    "This module imports necessary libraries and modules for graph processing,\n",
    "data manipulation, visualization, and language model interactions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf6c6d8-2e47-4764-a4d5-b4c1a839e2f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: .DS_Store in folder mongodump_full_snapshot\n",
      "Unsupported file format: license.txt in folder mongodump_full_snapshot\n",
      "Folder '/Users/sylvesterduah/Documents/Code/De_Alignment/data/raw/aiidprob' does not exist. Skipping.\n",
      "Folder '/Users/sylvesterduah/Documents/Code/De_Alignment/data/raw/translations' does not exist. Skipping.\n",
      "Dataset: mongodump_full_snapshot_classifications_GMF\n",
      "  Namespace  Incident ID  Published  \\\n",
      "0       GMF            1       True   \n",
      "1       GMF           13       True   \n",
      "2       GMF           31       True   \n",
      "3       GMF           34       True   \n",
      "4       GMF           36       True   \n",
      "\n",
      "                                       Known AI Goal  \\\n",
      "0  Content Recommendation, Content Search, Hate S...   \n",
      "1                              Hate Speech Detection   \n",
      "2                                 Autonomous Driving   \n",
      "3                                 AI Voice Assistant   \n",
      "4                                   Face Recognition   \n",
      "\n",
      "                              Known AI Goal Snippets  \\\n",
      "0  Snippet Text: An off-brand Paw Patrol video ca...   \n",
      "1  Snippet Text: However, computer scientists and...   \n",
      "2  Snippet Text: New Delhi, Dec 20 (IANS) The Del...   \n",
      "3  Snippet Text: According to one couple on Twitt...   \n",
      "4  Snippet Text: Chinese AI traffic cam mistook a...   \n",
      "\n",
      "             Known AI Goal Classification Discussion Potential AI Goal  \\\n",
      "0                                                NaN               NaN   \n",
      "1                                                NaN               NaN   \n",
      "2                                                NaN               NaN   \n",
      "3                                                NaN               NaN   \n",
      "4  Face Recognition: i.e. the context of ‘not a l...               NaN   \n",
      "\n",
      "  Potential AI Goal Snippets Potential AI Goal Classification Discussion  \\\n",
      "0                        NaN                                         NaN   \n",
      "1                        NaN                                         NaN   \n",
      "2                        NaN                                         NaN   \n",
      "3                        NaN                                         NaN   \n",
      "4                        NaN                                         NaN   \n",
      "\n",
      "                                 Known AI Technology  ...  \\\n",
      "0   Content-based Filtering, Collaborative Filtering  ...   \n",
      "1                                   Character NGrams  ...   \n",
      "2                                                NaN  ...   \n",
      "3  Automatic Speech Recognition, Language Modelin...  ...   \n",
      "4                                                NaN  ...   \n",
      "\n",
      "  Known AI Technology Classification Discussion  \\\n",
      "0                                           NaN   \n",
      "1                                           NaN   \n",
      "2                                           NaN   \n",
      "3                                           NaN   \n",
      "4                                           NaN   \n",
      "\n",
      "                             Potential AI Technology  \\\n",
      "0  Classification, Ensemble Aggregation, Distribu...   \n",
      "1                            Distributional Learning   \n",
      "2                   Other domain-specific approaches   \n",
      "3                                                NaN   \n",
      "4  Face Detection, Ensemble Aggregation, Convolut...   \n",
      "\n",
      "                    Potential AI Technology Snippets  \\\n",
      "0  Snippet Text: \\nPart of YouTube’s plan is to i...   \n",
      "1  Snippet Text: The Google AI tool used to flag ...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  Snippet Text: Chinese AI traffic cam mistook a...   \n",
      "\n",
      "   Potential AI Technology Classification Discussion  \\\n",
      "0  Classification: Appropriateness could arise by...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  Face Detection: i.e. the context of ‘not a liv...   \n",
      "\n",
      "                          Known AI Technical Failure  \\\n",
      "0  Tuning Issues, Lack of Adversarial Robustness,...   \n",
      "1  Context Misidentification, Generalization Fail...   \n",
      "2                                                NaN   \n",
      "3                  Unsafe Exposure or Access, Misuse   \n",
      "4                                                NaN   \n",
      "\n",
      "                 Known AI Technical Failure Snippets  \\\n",
      "0  Snippet Text: \\nPart of YouTube’s plan is to i...   \n",
      "1  Snippet Text: “This is essentially finding ‘go...   \n",
      "2                                                NaN   \n",
      "3  Snippet Text: Alexa is not without its SNAFUs ...   \n",
      "4                                                NaN   \n",
      "\n",
      "  Known AI Technical Failure Classification Discussion  \\\n",
      "0  Tuning Issues: Default classification, in case...     \n",
      "1                                                NaN     \n",
      "2                                                NaN     \n",
      "3                                                NaN     \n",
      "4                                                NaN     \n",
      "\n",
      "                      Potential AI Technical Failure  \\\n",
      "0  Concept Drift, Generalization Failure, Misconf...   \n",
      "1  Limited Dataset, Misaligned Objective, Underfi...   \n",
      "2                           Hardware Failure, Misuse   \n",
      "3  Unauthorized Data, Inadequate Anonymization, C...   \n",
      "4  Context Misidentification, Data or Labelling N...   \n",
      "\n",
      "             Potential AI Technical Failure Snippets  \\\n",
      "0  Snippet Text: “From a child standpoint, the pr...   \n",
      "1  Snippet Text: It’s very limited to the types o...   \n",
      "2  Snippet Text: New Delhi, Dec 20 (IANS) The Del...   \n",
      "3  Snippet Text: The device starts recording when...   \n",
      "4  Snippet Text: Chinese AI traffic cam mistook a...   \n",
      "\n",
      "  Potential AI Technical Failure Classification Discussion  \n",
      "0  Concept Drift: Concept drift in cases where ap...        \n",
      "1  Data or Labelling Noise: Potentially profanity...        \n",
      "2                                                NaN        \n",
      "3  Unauthorized Data: This may apply on an ethica...        \n",
      "4  Context Misidentification: i.e. the context of...        \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_duplicates\n",
      "   duplicate_incident_number  true_incident_number\n",
      "0                        237                   120\n",
      "1                        130                   107\n",
      "2                        247                   246\n",
      "3                        512                   506\n",
      "4                        637                   112\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_classifications_CSETv1_Annotator-1\n",
      "            Namespace  Incident ID  Published  Incident Number  Annotator  \\\n",
      "0  CSETv1_Annotator-1           22       True               22          5   \n",
      "1  CSETv1_Annotator-1           20       True               20          5   \n",
      "2  CSETv1_Annotator-1           52       True               52          5   \n",
      "3  CSETv1_Annotator-1           18       True               18          5   \n",
      "4  CSETv1_Annotator-1           19       True               19          5   \n",
      "\n",
      "         Annotation Status  Peer Reviewer  Quality Control Physical Objects  \\\n",
      "0  4. Peer review complete            2.0            False              yes   \n",
      "1  4. Peer review complete            2.0            False              yes   \n",
      "2    6. Complete and final            NaN            False              NaN   \n",
      "3  4. Peer review complete            3.0            False               no   \n",
      "4  4. Peer review complete            2.0            False               no   \n",
      "\n",
      "  Entertainment Industry  ...                                    Data Inputs  \\\n",
      "0                     no  ...     user traffic reports, route specifications   \n",
      "1                     no  ...  video input, sensor data, radar, camera input   \n",
      "2                    NaN  ...                                            NaN   \n",
      "3                     no  ...                       keywords, search queries   \n",
      "4                     no  ...                                 search queries   \n",
      "\n",
      "                                Sector of Deployment Public Sector Deployment  \\\n",
      "0  transportation and storage, information and co...                       no   \n",
      "1                         transportation and storage                       no   \n",
      "2                                                NaN                      NaN   \n",
      "3                      information and communication                       no   \n",
      "4                      information and communication                       no   \n",
      "\n",
      "  Autonomy Level                Notes (Information about AI System)  \\\n",
      "0      Autonomy3                                                NaN   \n",
      "1      Autonomy2  Autopilot is a semiautonomous driving-assistan...   \n",
      "2            NaN                                                NaN   \n",
      "3      Autonomy1                                                NaN   \n",
      "4      Autonomy1                                                NaN   \n",
      "\n",
      "                                 Intentional Harm  \\\n",
      "0  No. Not intentionally designed to perform harm   \n",
      "1  No. Not intentionally designed to perform harm   \n",
      "2                                             NaN   \n",
      "3  No. Not intentionally designed to perform harm   \n",
      "4  No. Not intentionally designed to perform harm   \n",
      "\n",
      "                        Physical System Type  \\\n",
      "0                                        NaN   \n",
      "1  Tesla vehicle (Model 3, Model S, Model X)   \n",
      "2                                 Automobile   \n",
      "3                                        NaN   \n",
      "4                                        NaN   \n",
      "\n",
      "                                             AI Task  \\\n",
      "0                     navigation, route optimization   \n",
      "1  navigation, transportation, semi-autonomous na...   \n",
      "2                                                NaN   \n",
      "3  search optimization, personalized online searc...   \n",
      "4  smart suggestions, search result ranking, pers...   \n",
      "\n",
      "                          AI tools and methods  \\\n",
      "0  shortest-path algorithm, Dijkstra Algorithm   \n",
      "1                          audiovisual sensing   \n",
      "2                                          NaN   \n",
      "3                                 web scraping   \n",
      "4                                          NaN   \n",
      "\n",
      "  Notes (AI Functionality and Techniques)  \n",
      "0                                     NaN  \n",
      "1                                     NaN  \n",
      "2                                     NaN  \n",
      "3                                     NaN  \n",
      "4                                     NaN  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_classifications_CSETv1_Annotator-2\n",
      "            Namespace  Incident ID  Published  Incident Number  Annotator  \\\n",
      "0  CSETv1_Annotator-2           55       True               55          6   \n",
      "1  CSETv1_Annotator-2           46       True               46          6   \n",
      "2  CSETv1_Annotator-2           44       True               44          6   \n",
      "3  CSETv1_Annotator-2           41       True               41          6   \n",
      "4  CSETv1_Annotator-2           39       True               39          6   \n",
      "\n",
      "                Annotation Status  Peer Reviewer  Quality Control  \\\n",
      "0               3. In peer review            3.0            False   \n",
      "1  2. Initial annotation complete            NaN            False   \n",
      "2  2. Initial annotation complete            NaN            False   \n",
      "3               3. In peer review            2.0            False   \n",
      "4               3. In peer review            3.0            False   \n",
      "\n",
      "  Physical Objects Entertainment Industry  ...                  Data Inputs  \\\n",
      "0              yes                     no  ...  voice, audio, personal data   \n",
      "1              yes                     no  ...                          NaN   \n",
      "2               no                     no  ...     schedules, personal data   \n",
      "3               no                     no  ...               Text, Captions   \n",
      "4               no                     no  ...                 video, audio   \n",
      "\n",
      "         Sector of Deployment Public Sector Deployment Autonomy Level  \\\n",
      "0  wholesale and retail trade                       no      Autonomy2   \n",
      "1                         NaN                      NaN      Autonomy1   \n",
      "2                       other                       no      Autonomy2   \n",
      "3                         NaN                       no      Autonomy2   \n",
      "4                       other                       no      Autonomy3   \n",
      "\n",
      "  Notes (Information about AI System)  \\\n",
      "0                                 NaN   \n",
      "1                                 NaN   \n",
      "2                                 NaN   \n",
      "3                                 NaN   \n",
      "4                                 NaN   \n",
      "\n",
      "                                 Intentional Harm Physical System Type  \\\n",
      "0  No. Not intentionally designed to perform harm         Amazon Alexa   \n",
      "1  No. Not intentionally designed to perform harm                  NaN   \n",
      "2  No. Not intentionally designed to perform harm                  NaN   \n",
      "3  No. Not intentionally designed to perform harm                  NaN   \n",
      "4  No. Not intentionally designed to perform harm                  NaN   \n",
      "\n",
      "              AI Task                               AI tools and methods  \\\n",
      "0   Digital Assistant  Natural Language Processesing, Text to Speach,...   \n",
      "1                 NaN                                                NaN   \n",
      "2  Personal Assistant                                                NaN   \n",
      "3   Generate Captions                      Natural Language Processesing   \n",
      "4            Deepfake                                                NaN   \n",
      "\n",
      "  Notes (AI Functionality and Techniques)  \n",
      "0                                     NaN  \n",
      "1                                     NaN  \n",
      "2                                     NaN  \n",
      "3                                     NaN  \n",
      "4                                     NaN  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_classifications_CSETv1_Annotator-3\n",
      "            Namespace  Incident ID  Published  Incident Number  Annotator  \\\n",
      "0  CSETv1_Annotator-3          100       True            100.0        7.0   \n",
      "1  CSETv1_Annotator-3           95      False              NaN        NaN   \n",
      "2  CSETv1_Annotator-3           86       True             86.0        7.0   \n",
      "3  CSETv1_Annotator-3           84       True             84.0        7.0   \n",
      "4  CSETv1_Annotator-3           99      False             99.0        7.0   \n",
      "\n",
      "                Annotation Status  Peer Reviewer  Quality Control  \\\n",
      "0  2. Initial annotation complete            NaN            False   \n",
      "1                             NaN            NaN            False   \n",
      "2  2. Initial annotation complete            NaN            False   \n",
      "3         4. Peer review complete            3.0            False   \n",
      "4       1. Annotation in progress            NaN            False   \n",
      "\n",
      "  Physical Objects Entertainment Industry  ...     Data Inputs  \\\n",
      "0               no                     no  ...             NaN   \n",
      "1               no                     no  ...          videos   \n",
      "2               no                     no  ...         Unclear   \n",
      "3               no                     no  ...  Facebook posts   \n",
      "4               no                     no  ...             NaN   \n",
      "\n",
      "                                Sector of Deployment Public Sector Deployment  \\\n",
      "0  financial and insurance activities, administra...                      yes   \n",
      "1      administrative and support service activities                       no   \n",
      "2                   Education, public administration                      yes   \n",
      "3                      information and communication                       no   \n",
      "4  administrative and support service activities,...                    maybe   \n",
      "\n",
      "  Autonomy Level                Notes (Information about AI System)  \\\n",
      "0      Autonomy2                                                NaN   \n",
      "1        unclear  I seems that it is independent but it is not e...   \n",
      "2        unclear                                                NaN   \n",
      "3      Autonomy1                                                NaN   \n",
      "4        unclear                                                NaN   \n",
      "\n",
      "                                 Intentional Harm Physical System Type  \\\n",
      "0  No. Not intentionally designed to perform harm                  NaN   \n",
      "1  No. Not intentionally designed to perform harm                  NaN   \n",
      "2  No. Not intentionally designed to perform harm                  NaN   \n",
      "3  No. Not intentionally designed to perform harm                  NaN   \n",
      "4  No. Not intentionally designed to perform harm                  NaN   \n",
      "\n",
      "           AI Task AI tools and methods  \\\n",
      "0              NaN                  NaN   \n",
      "1  recruiting tool                  NaN   \n",
      "2  grade predictor                  NaN   \n",
      "3       fact-check                  NaN   \n",
      "4  risk prediction                  NaN   \n",
      "\n",
      "             Notes (AI Functionality and Techniques)  \n",
      "0                                    Fraud detection  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3  Facebook's artificial intelligence system is u...  \n",
      "4                                                NaN  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_submissions\n",
      "Empty DataFrame\n",
      "Columns: [authors, date_downloaded, date_modified, date_published, date_submitted, image_url, incident_date, incident_id, language, mongodb_id, source_domain, submitters, text, title, url]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_classifications_CSETv0\n",
      "  Namespace  Incident ID  Published  Annotator      Annotation Status  \\\n",
      "0    CSETv0            5       True          2  6. Complete and final   \n",
      "1    CSETv0            3      False          1  6. Complete and final   \n",
      "2    CSETv0           48       True          4  6. Complete and final   \n",
      "3    CSETv0           77       True          5  6. Complete and final   \n",
      "4    CSETv0           67       True          6  6. Complete and final   \n",
      "\n",
      "   Reviewer Quality Control  \\\n",
      "0         2           False   \n",
      "1         6           False   \n",
      "2         6           False   \n",
      "3         2           False   \n",
      "4         2           False   \n",
      "\n",
      "                                    Full Description  \\\n",
      "0  Reports of robotic surgeries resulting in inju...   \n",
      "1  A Boeing 737 MAX aircraft equipped with a new,...   \n",
      "2  Richard Lee, a New Zealander of Asian descent ...   \n",
      "3  A Knightscope K5 autonomous security robot was...   \n",
      "4  A Tesla Model S continued autopilot at 70 mph ...   \n",
      "\n",
      "                                   Short Description  \\\n",
      "0  Study on database reports of robotic surgery m...   \n",
      "1  A Boeing 737 crashed into the sea, killing 189...   \n",
      "2  New Zealand passport robot reader rejects the ...   \n",
      "3  In Fall 2018, a Knightscope K5 autonomous secu...   \n",
      "4  A Tesla Model S remained on autopilot while be...   \n",
      "\n",
      "             Beginning Date  ... System Developer  \\\n",
      "0  2000-01-01T00:00:00.000Z  ...              NaN   \n",
      "1                2018-10-29  ...           Boeing   \n",
      "2                   12/2016  ...              NaN   \n",
      "3                2018-01-01  ...      Knightscope   \n",
      "4  2018-11-30T08:00:00.000Z  ...            Tesla   \n",
      "\n",
      "                            Sector of Deployment Public Sector Deployment  \\\n",
      "0        Human health and social work activities                    False   \n",
      "1                     Transportation and storage                    False   \n",
      "2  Administrative and support service activities                    False   \n",
      "3  Administrative and support service activities                    False   \n",
      "4                     Transportation and storage                    False   \n",
      "\n",
      "  Nature of End User Level of Autonomy          Relevant AI functions  \\\n",
      "0             Expert               Low                         Action   \n",
      "1             Expert              High  Perception, Cognition, Action   \n",
      "2            Amateur            Medium  Perception, Cognition, Action   \n",
      "3            Amateur              High  Perception, Cognition, Action   \n",
      "4            Amateur              High  Perception, Cognition, Action   \n",
      "\n",
      "           AI Techniques                                    AI Applications  \\\n",
      "0  Robotic surgery tools                                    Robotic Surgery   \n",
      "1                    NaN      Aircraft maneuvering, sensor input processing   \n",
      "2     Facial recognition                                 Facial recognition   \n",
      "3                unknown  Image classification, image recognition, facia...   \n",
      "4        Tesla Autopilot          autonomous driving, environmental sensing   \n",
      "\n",
      "                      Physical System             Problem Nature  \n",
      "0                Other:Medical system      Robustness, Assurance  \n",
      "1                Vehicle/mobile robot      Robustness, Assurance  \n",
      "2                       Software only            Unknown/unclear  \n",
      "3                Vehicle/mobile robot            Unknown/unclear  \n",
      "4  Vehicle/mobile robot, Other:Camera  Specification, Robustness  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_classifications_CSETv1\n",
      "  Namespace  Incident ID  Published  Incident Number  Annotator  \\\n",
      "0    CSETv1          204      False                0        NaN   \n",
      "1    CSETv1          350      False                0        NaN   \n",
      "2    CSETv1          250      False                0        NaN   \n",
      "3    CSETv1          208      False                0        NaN   \n",
      "4    CSETv1          100       True              100        3.0   \n",
      "\n",
      "         Annotation Status  Peer Reviewer  Quality Control Physical Objects  \\\n",
      "0                       --            NaN            False              NaN   \n",
      "1                       --            NaN            False              NaN   \n",
      "2                       --            NaN            False              NaN   \n",
      "3                       --            NaN            False              NaN   \n",
      "4  4. Peer review complete            1.0            False               no   \n",
      "\n",
      "  Entertainment Industry  ...             Data Inputs  \\\n",
      "0                    NaN  ...                     NaN   \n",
      "1                    NaN  ...                     NaN   \n",
      "2                    NaN  ...                     NaN   \n",
      "3                    NaN  ...                     NaN   \n",
      "4                     no  ...  welfare recipient data   \n",
      "\n",
      "                                Sector of Deployment Public Sector Deployment  \\\n",
      "0                                                NaN                      NaN   \n",
      "1                                                NaN                       no   \n",
      "2                                                NaN                      NaN   \n",
      "3                                                NaN                      NaN   \n",
      "4  administrative and support service activities,...                      yes   \n",
      "\n",
      "  Autonomy Level Notes (Information about AI System)  \\\n",
      "0            NaN                                 NaN   \n",
      "1            NaN                                 NaN   \n",
      "2            NaN                                 NaN   \n",
      "3            NaN                                 NaN   \n",
      "4      Autonomy2                                 NaN   \n",
      "\n",
      "                                 Intentional Harm Physical System Type  \\\n",
      "0                                             NaN                  NaN   \n",
      "1                                             NaN                  NaN   \n",
      "2                                             NaN                  NaN   \n",
      "3                                             NaN                  NaN   \n",
      "4  No. Not intentionally designed to perform harm                  NaN   \n",
      "\n",
      "                 AI Task AI tools and methods  \\\n",
      "0                    NaN                  NaN   \n",
      "1                    NaN                  NaN   \n",
      "2                    NaN                  NaN   \n",
      "3                    NaN                  NaN   \n",
      "4  welfare determination                  NaN   \n",
      "\n",
      "  Notes (AI Functionality and Techniques)  \n",
      "0                                     NaN  \n",
      "1                                     NaN  \n",
      "2                                     NaN  \n",
      "3                                     NaN  \n",
      "4                         Fraud detection  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_quickadd\n",
      "   incident_id                                                url  \\\n",
      "0            0  https://x.com/JohnClarkLevin/status/1886875135...   \n",
      "\n",
      "  date_submitted source_domain  \n",
      "0     2025-02-10         x.com  \n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_reports\n",
      "                                  _id  incident_id               authors  \\\n",
      "0  ObjectId(5d34b8c29ced494f010ed461)          NaN  [\"Sapna Maheshwari\"]   \n",
      "1  ObjectId(5d34b8c29ced494f010ed45b)          NaN     [\"Phoebe Weston\"]   \n",
      "2  ObjectId(5d34b8c29ced494f010ed462)          NaN        [\"James Cook\"]   \n",
      "3  ObjectId(5d34b8c29ced494f010ed465)          NaN        [\"Ben Popper\"]   \n",
      "4  ObjectId(5d34b8c29ced494f010ed467)          NaN      [\"Sara Perkins\"]   \n",
      "\n",
      "            date_downloaded             date_modified  \\\n",
      "0  2019-04-13T00:00:00.000Z  2020-06-14T00:00:00.000Z   \n",
      "1  2019-04-13T00:00:00.000Z  2020-06-14T00:00:00.000Z   \n",
      "2  2019-04-13T00:00:00.000Z  2020-06-14T00:00:00.000Z   \n",
      "3  2019-04-13T00:00:00.000Z  2020-06-14T00:00:00.000Z   \n",
      "4  2019-04-13T00:00:00.000Z  2020-06-14T00:00:00.000Z   \n",
      "\n",
      "             date_published            date_submitted  \\\n",
      "0  2018-04-26T00:00:00.000Z  2019-06-01T00:00:00.000Z   \n",
      "1  2018-02-07T00:00:00.000Z  2019-06-01T00:00:00.000Z   \n",
      "2  2018-03-17T00:00:00.000Z  2019-06-01T00:00:00.000Z   \n",
      "3  2017-11-10T00:00:00.000Z  2019-06-01T00:00:00.000Z   \n",
      "4  2018-11-16T00:00:00.000Z  2019-06-01T00:00:00.000Z   \n",
      "\n",
      "                                         description  epoch_date_downloaded  \\\n",
      "0  Parents will be able to handpick the channels ...             1555113600   \n",
      "1  Investigators found several unsuitable videos ...             1555113600   \n",
      "2  YouTube removed videos from conspiracy theoris...             1555113600   \n",
      "3  Videos that violate policy will now be age res...             1555113600   \n",
      "4  YouTube is more sinister than ever before, wit...             1555113600   \n",
      "\n",
      "   epoch_date_modified  ...  \\\n",
      "0         1.592093e+09  ...   \n",
      "1         1.592093e+09  ...   \n",
      "2         1.592093e+09  ...   \n",
      "3         1.592093e+09  ...   \n",
      "4         1.592093e+09  ...   \n",
      "\n",
      "                                           image_url  language ref_number  \\\n",
      "0  https://static01.nyt.com/images/2017/11/07/bus...        en        NaN   \n",
      "1  https://i.dailymail.co.uk/i/pix/2018/02/06/15/...        en        NaN   \n",
      "2  https://amp.businessinsider.com/images/5aaa960...        en        NaN   \n",
      "3  https://cdn.vox-cdn.com/thumbor/BP61zGpZ6VCx6H...        en        NaN   \n",
      "4  https://studybreaks.com/wp-content/uploads/201...        en        NaN   \n",
      "\n",
      "  report_number        source_domain            submitters  \\\n",
      "0             8          nytimes.com  [\"Roman Yampolskiy\"]   \n",
      "1             2      dailymail.co.uk  [\"Roman Yampolskiy\"]   \n",
      "2             9  businessinsider.com  [\"Roman Yampolskiy\"]   \n",
      "3            12         theverge.com  [\"Roman Yampolskiy\"]   \n",
      "4            14      studybreaks.com  [\"Roman Yampolskiy\"]   \n",
      "\n",
      "                                                text  \\\n",
      "0  YouTube Kids, which has been criticized for in...   \n",
      "1  Google-owned YouTube has apologised again afte...   \n",
      "2  Children were able to watch David Icke's consp...   \n",
      "3  Earlier this week, a report in The New York Ti...   \n",
      "4  YouTube is both a massive industry and browsin...   \n",
      "\n",
      "                                               title  \\\n",
      "0  YouTube Kids, Criticized for Content, Introduc...   \n",
      "1  YouTube Kids app is STILL showing disturbing v...   \n",
      "2  YouTube suggested conspiracy videos to childre...   \n",
      "3  YouTube says it will crack down on bizarre vid...   \n",
      "4  YouTube Kids Is Nowhere Near as Innocent As It...   \n",
      "\n",
      "                                                 url tags  \n",
      "0  https://www.nytimes.com/2018/04/25/business/me...   []  \n",
      "1  https://www.dailymail.co.uk/sciencetech/articl...   []  \n",
      "2  https://www.businessinsider.com/youtube-sugges...   []  \n",
      "3  https://www.theverge.com/2017/11/9/16629788/yo...   []  \n",
      "4  https://studybreaks.com/tvfilm/youtube-kids-is...   []  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "\n",
      "Dataset: mongodump_full_snapshot_incidents\n",
      "                                  _id  incident_id        date  \\\n",
      "0  ObjectId(625763db343edc875fe639ff)            1  2015-05-19   \n",
      "1  ObjectId(625763de343edc875fe63a15)           23  2017-11-08   \n",
      "2  ObjectId(625763dc343edc875fe63a02)            4  2018-03-18   \n",
      "3  ObjectId(625763dd343edc875fe63a0a)           12  2016-07-21   \n",
      "4  ObjectId(625763dc343edc875fe63a03)            5  2015-07-13   \n",
      "\n",
      "                                             reports  \\\n",
      "0                 [1,2,3,4,5,6,7,8,9,10,11,12,14,15]   \n",
      "1  [242,243,244,245,246,247,248,249,250,253,254,2...   \n",
      "2  [629,630,631,632,633,634,635,636,637,638,639,6...   \n",
      "3                                               [42]   \n",
      "4  [767,768,769,770,771,772,773,774,775,776,777,778]   \n",
      "\n",
      "                Alleged deployer of AI system  \\\n",
      "0                                 [\"youtube\"]   \n",
      "1            [\"navya\",\"keolis-north-america\"]   \n",
      "2                                    [\"uber\"]   \n",
      "3  [\"microsoft-research\",\"boston-university\"]   \n",
      "4                     [\"hospitals\",\"doctors\"]   \n",
      "\n",
      "                      Alleged developer of AI system  \\\n",
      "0                                        [\"youtube\"]   \n",
      "1                   [\"navya\",\"keolis-north-america\"]   \n",
      "2                                           [\"uber\"]   \n",
      "3  [\"microsoft-research\",\"google\",\"boston-univers...   \n",
      "4                             [\"intuitive-surgical\"]   \n",
      "\n",
      "             Alleged harmed or nearly harmed parties  \\\n",
      "0                                       [\"children\"]   \n",
      "1  [\"navya\",\"keolis-north-america\",\"bus-passengers\"]   \n",
      "2                  [\"elaine-herzberg\",\"pedestrians\"]   \n",
      "3                        [\"women\",\"minority-groups\"]   \n",
      "4                                       [\"patients\"]   \n",
      "\n",
      "                                         description  \\\n",
      "0  YouTube’s content filtering and recommendation...   \n",
      "1  A self-driving public shuttle by Keolis North ...   \n",
      "2  An Uber autonomous vehicle (AV) in autonomous ...   \n",
      "3  Researchers from Boston University and Microso...   \n",
      "4  Study on database reports of robotic surgery m...   \n",
      "\n",
      "                                               title  \n",
      "0  Google’s YouTube Kids App Presents Inappropria...  \n",
      "1    Las Vegas Self-Driving Bus Involved in Accident  \n",
      "2               Uber AV Killed Pedestrian in Arizona  \n",
      "3                 Common Biases of Vector Embeddings  \n",
      "4         Collection of Robotic Surgery Malfunctions  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The cell to check and read the raw data\n",
    "BASE_RAW_DATA_FOLDER: str = os.path.expanduser(\"~/Documents/Code/De_Alignment/data/raw/\")\n",
    "\n",
    "# Folders to view and process\n",
    "folders_to_process = [\"mongodump_full_snapshot\", \"aiidprob\", \"translations\"]\n",
    "\n",
    "# Store datasets into dictionary\n",
    "datasets = {}\n",
    "\n",
    "# Read json files\n",
    "def read_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Read bson files\n",
    "def read_bson(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return loads(f.read())\n",
    "\n",
    "# Iteration through the folders\n",
    "for folder in folders_to_process:\n",
    "    folder_path = os.path.join(BASE_RAW_DATA_FOLDER, folder)  # Changed variable name here\n",
    "    \n",
    "    # Checking if the folders exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder '{folder_path}' does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Exact all files in the folders\n",
    "    raw_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    # Read them\n",
    "    for file in raw_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        dataset_name = f\"{folder}_{os.path.splitext(file)[0]}\"  # Include folder name in dataset key\n",
    "\n",
    "        try:\n",
    "            # Check if the files extensions are correct\n",
    "            if file.endswith('.csv'):\n",
    "                datasets[dataset_name] = pd.read_csv(file_path)\n",
    "            elif file.endswith('.json'):\n",
    "                datasets[dataset_name] = pd.DataFrame(read_json(file_path))\n",
    "            elif file.endswith('.bson'):\n",
    "                datasets[dataset_name] = pd.DataFrame(read_bson(file_path))\n",
    "            else:\n",
    "                print(f\"Unsupported file format: {file} in folder {folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file} in folder {folder}: {e}\")\n",
    "\n",
    "# Print preview of the dtasets for verifaction\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb61c7a-9612-44c1-aaeb-6567ae2c5059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping dataset 'mongodump_full_snapshot_classifications_CSETv1_Annotator-1' as it does not match any predefined structure.\n",
      "Skipping dataset 'mongodump_full_snapshot_classifications_CSETv1_Annotator-2' as it does not match any predefined structure.\n",
      "Skipping dataset 'mongodump_full_snapshot_classifications_CSETv1_Annotator-3' as it does not match any predefined structure.\n",
      "Skipping dataset 'mongodump_full_snapshot_submissions' as it does not match any predefined structure.\n",
      "Skipping dataset 'mongodump_full_snapshot_classifications_CSETv0' as it does not match any predefined structure.\n",
      "Skipping dataset 'mongodump_full_snapshot_classifications_CSETv1' as it does not match any predefined structure.\n",
      "Skipping dataset 'mongodump_full_snapshot_quickadd' as it does not match any predefined structure.\n",
      "Successfully processed and saved data for 'mongodump_full_snapshot_classifications_GMF'\n",
      "Successfully processed and saved data for 'mongodump_full_snapshot_duplicates'\n",
      "Successfully processed and saved data for 'mongodump_full_snapshot_reports'\n",
      "Successfully processed and saved data for 'mongodump_full_snapshot_incidents'\n",
      "Data preprocessing complete! Processed data saved in 'processed/'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/j2lypjp93_x38wr0rthx_ymh0000gn/T/ipykernel_47887/1844500308.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edges['weight'] = 1\n",
      "/var/folders/7q/j2lypjp93_x38wr0rthx_ymh0000gn/T/ipykernel_47887/1844500308.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edges['weight'] = 1\n",
      "/var/folders/7q/j2lypjp93_x38wr0rthx_ymh0000gn/T/ipykernel_47887/1844500308.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edges['weight'] = 1\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Custom preprocessing function to extract nodes and edges based on dataset name.\n",
    "    \"\"\"\n",
    "    nodes = None\n",
    "    edges = None\n",
    "\n",
    "    if dataset_name == \"mongodump_full_snapshot_duplicates\":\n",
    "        nodes = pd.concat([dataset['duplicate_incident_number'], dataset['true_incident_number']]).unique()\n",
    "        edges = dataset[['duplicate_incident_number', 'true_incident_number']]\n",
    "        edges['weight'] = 1  \n",
    "        \n",
    "    elif dataset_name == \"mongodump_full_snapshot_incidents\":\n",
    "        dataset['Alleged deployer of AI system'] = dataset['Alleged deployer of AI system'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "        dataset['Alleged developer of AI system'] = dataset['Alleged developer of AI system'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "        nodes = pd.concat([dataset['Alleged deployer of AI system'], dataset['Alleged developer of AI system']]).unique()\n",
    "        edges = dataset[['Alleged deployer of AI system', 'Alleged developer of AI system']]\n",
    "        edges['weight'] = 1\n",
    "\n",
    "    elif dataset_name == \"mongodump_full_snapshot_reports\":\n",
    "        dataset['authors'] = dataset['authors'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "        nodes = pd.concat([dataset['authors'], dataset['source_domain']]).unique()\n",
    "        edges = dataset[['authors', 'source_domain']]\n",
    "        edges['weight'] = 1 \n",
    "\n",
    "    elif dataset_name == \"mongodump_full_snapshot_classifications_GMF\":\n",
    "        nodes = pd.concat([dataset['Known AI Goal'], dataset['Known AI Technology']]).unique()\n",
    "        edges = dataset[['Known AI Goal', 'Known AI Technology']]\n",
    "        edges['weight'] = 1 \n",
    "        \n",
    "    else:\n",
    "        print(f\"Skipping dataset '{dataset_name}' as it does not match any predefined structure.\")\n",
    "        return None, None\n",
    "\n",
    "    nodes_df = pd.DataFrame(nodes, columns=[\"node\"])\n",
    "\n",
    "    return nodes_df, edges\n",
    "\n",
    "# Preprocess all datasets\n",
    "processed_data = {}\n",
    "for name, dataset in datasets.items():\n",
    "    try:\n",
    "        nodes, edges = preprocess_data(dataset, name)\n",
    "        if nodes is not None and edges is not None:\n",
    "            processed_data[name] = {\"nodes\": nodes, \"edges\": edges}\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing dataset '{name}': {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Save processed data\n",
    "processed_data_folder = \"processed/\"\n",
    "os.makedirs(processed_data_folder, exist_ok=True)\n",
    "\n",
    "for name, data in processed_data.items():\n",
    "    try:\n",
    "        # Save nodes\n",
    "        data[\"nodes\"].to_csv(os.path.join(processed_data_folder, f\"{name}_nodes.csv\"), index=False)\n",
    "\n",
    "        # Save edges\n",
    "        data[\"edges\"].to_csv(os.path.join(processed_data_folder, f\"{name}_edges.csv\"), index=False)\n",
    "\n",
    "        print(f\"Successfully processed and saved data for '{name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving processed data for '{name}': {str(e)}\")\n",
    "\n",
    "print(\"Data preprocessing complete! Processed data saved in 'processed/'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "align",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
